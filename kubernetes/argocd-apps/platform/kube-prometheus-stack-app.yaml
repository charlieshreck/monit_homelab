---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "3"
spec:
  project: monitoring
  source:
    repoURL: https://prometheus-community.github.io/helm-charts
    chart: kube-prometheus-stack
    targetRevision: 69.3.1
    helm:
      valuesObject:
        # Prometheus configuration
        prometheus:
          prometheusSpec:
            retention: 30d
            retentionSize: "45GB"
            storageSpec:
              volumeClaimTemplate:
                spec:
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 50Gi
            resources:
              requests:
                cpu: 500m
                memory: 2Gi
              limits:
                cpu: 2000m
                memory: 4Gi
            # Mount production cluster credentials
            secrets:
              - production-cluster-credentials
            # Enable remote write to VictoriaMetrics
            remoteWrite:
              - url: http://victoria-metrics-victoria-metrics-single-server:8428/api/v1/write
                queueConfig:
                  capacity: 10000
                  maxShards: 30
                  minShards: 1
                  maxSamplesPerSend: 5000
                  batchSendDeadline: 5s
                  minBackoff: 30ms
                  maxBackoff: 100ms
            # Scrape configs for monitoring targets
            additionalScrapeConfigs:
              # Proxmox Ruapehu (production)
              - job_name: 'proxmox-ruapehu'
                scheme: https
                tls_config:
                  insecure_skip_verify: true
                basic_auth:
                  username: root@pam
                  password: H4ckwh1z
                static_configs:
                  - targets: ['10.10.0.10:8006']
                metrics_path: '/api2/prometheus'
                params:
                  format: ['prometheus']
              # Proxmox Carrick (monitoring)
              - job_name: 'proxmox-carrick'
                scheme: https
                tls_config:
                  insecure_skip_verify: true
                basic_auth:
                  username: root@pam
                  password: H4ckwh1z
                static_configs:
                  - targets: ['10.30.0.10:8006']
                metrics_path: '/api2/prometheus'
                params:
                  format: ['prometheus']

              # Production Talos Cluster - Kubelet Metrics (via API server proxy)
              - job_name: 'talos-kubelets'
                scheme: https
                tls_config:
                  ca_file: /etc/prometheus/secrets/production-cluster-credentials/ca.crt
                  insecure_skip_verify: false
                bearer_token_file: /etc/prometheus/secrets/production-cluster-credentials/token
                kubernetes_sd_configs:
                  - role: node
                    api_server: 'https://10.10.0.40:6443'
                    tls_config:
                      ca_file: /etc/prometheus/secrets/production-cluster-credentials/ca.crt
                    bearer_token_file: /etc/prometheus/secrets/production-cluster-credentials/token
                relabel_configs:
                  - action: labelmap
                    regex: __meta_kubernetes_node_label_(.+)
                  - target_label: __address__
                    replacement: 10.10.0.40:6443
                  - source_labels: [__meta_kubernetes_node_name]
                    regex: (.+)
                    target_label: __metrics_path__
                    replacement: /api/v1/nodes/${1}/proxy/metrics
                  - target_label: cluster
                    replacement: production

              # Production Talos Cluster - cAdvisor Metrics (via API server proxy)
              - job_name: 'talos-cadvisor'
                scheme: https
                tls_config:
                  ca_file: /etc/prometheus/secrets/production-cluster-credentials/ca.crt
                  insecure_skip_verify: false
                bearer_token_file: /etc/prometheus/secrets/production-cluster-credentials/token
                kubernetes_sd_configs:
                  - role: node
                    api_server: 'https://10.10.0.40:6443'
                    tls_config:
                      ca_file: /etc/prometheus/secrets/production-cluster-credentials/ca.crt
                    bearer_token_file: /etc/prometheus/secrets/production-cluster-credentials/token
                relabel_configs:
                  - action: labelmap
                    regex: __meta_kubernetes_node_label_(.+)
                  - target_label: __address__
                    replacement: 10.10.0.40:6443
                  - source_labels: [__meta_kubernetes_node_name]
                    regex: (.+)
                    target_label: __metrics_path__
                    replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
                  - target_label: cluster
                    replacement: production

              # Production Talos Cluster - API Server
              - job_name: 'talos-apiserver'
                scheme: https
                tls_config:
                  ca_file: /etc/prometheus/secrets/production-cluster-credentials/ca.crt
                  insecure_skip_verify: false
                bearer_token_file: /etc/prometheus/secrets/production-cluster-credentials/token
                static_configs:
                  - targets: ['10.10.0.40:6443']
                    labels:
                      cluster: 'production'
                metrics_path: '/metrics'

              # K3s monitoring cluster - kubelet metrics
              - job_name: 'k3s-monitor'
                scheme: https
                tls_config:
                  insecure_skip_verify: true
                bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
                static_configs:
                  - targets: ['10.30.0.20:10250']
                    labels:
                      cluster: 'monitoring'
                metrics_path: '/metrics'

        # Grafana configuration
        grafana:
          enabled: true
          adminPassword: H4ckwh1z
          persistence:
            enabled: true
            size: 10Gi
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 500m
              memory: 512Mi
          datasources:
            datasources.yaml:
              apiVersion: 1
              datasources:
                - name: Prometheus
                  type: prometheus
                  url: http://kube-prometheus-stack-prometheus:9090
                  isDefault: true
                  access: proxy
                  uid: prometheus
                  jsonData:
                    httpMethod: POST
                    timeInterval: 30s
                - name: VictoriaMetrics
                  type: prometheus
                  url: http://victoria-metrics-victoria-metrics-single-server:8428
                  access: proxy
                  uid: victoriametrics
                  isDefault: false
                  jsonData:
                    httpMethod: POST
                    timeInterval: 30s
                - name: VictoriaLogs
                  type: loki
                  url: http://victoria-logs-victoria-logs-single-server:9428/select/logsql
                  access: proxy
                  uid: victorialogs
                  isDefault: false
                  jsonData:
                    maxLines: 1000
          dashboardProviders:
            dashboardproviders.yaml:
              apiVersion: 1
              providers:
                - name: 'default'
                  orgId: 1
                  folder: ''
                  type: file
                  disableDeletion: false
                  editable: true
                  options:
                    path: /var/lib/grafana/dashboards/default

        # AlertManager configuration
        alertmanager:
          enabled: true
          alertmanagerSpec:
            storage:
              volumeClaimTemplate:
                spec:
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 10Gi
            resources:
              requests:
                cpu: 50m
                memory: 128Mi
              limits:
                cpu: 200m
                memory: 256Mi

        # Node exporter
        nodeExporter:
          enabled: true

        # Kube-state-metrics
        kubeStateMetrics:
          enabled: true

        # Default rules
        defaultRules:
          create: true
          rules:
            alertmanager: true
            etcd: false  # No etcd in K3s
            kubeApiserver: true
            kubeScheduler: true
            kubeControllerManager: true
            kubelet: true
            kubeProxy: true
            node: true
            prometheus: true

  destination:
    server: https://10.30.0.20:6443
    namespace: monitoring

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
